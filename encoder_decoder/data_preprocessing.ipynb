{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'data_preprocessing.ipynb']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_dir = os.getcwd()\n",
    "os.listdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder_decoder', 'eng2ben - collateral.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.path.join(working_dir, '..')\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Bengali</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- You okay? - Yeah, I'm fine, mate.</td>\n",
       "      <td>- আপানি ঠিক আছেন? - হ্যাঁ, আমি ভালো আছি, ভায়া।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Don't worry about it.</td>\n",
       "      <td>এটা নিয়ে একদম চিন্তা করবেন না।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You all right?</td>\n",
       "      <td>আপনি ঠিক আছেন তো?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enjoy L.A.</td>\n",
       "      <td>লস এঞ্জেলেসে আসাটা উপভোগ্য হোক।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- He did it. - It's all right.</td>\n",
       "      <td>- সে সেটা করেছিলো। - হুম ঠিক আছে।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               English  \\\n",
       "0  - You okay? - Yeah, I'm fine, mate.   \n",
       "1                Don't worry about it.   \n",
       "2                       You all right?   \n",
       "3                           Enjoy L.A.   \n",
       "4       - He did it. - It's all right.   \n",
       "\n",
       "                                          Bengali  \n",
       "0  - আপানি ঠিক আছেন? - হ্যাঁ, আমি ভালো আছি, ভায়া।  \n",
       "1                  এটা নিয়ে একদম চিন্তা করবেন না।  \n",
       "2                               আপনি ঠিক আছেন তো?  \n",
       "3                 লস এঞ্জেলেসে আসাটা উপভোগ্য হোক।  \n",
       "4               - সে সেটা করেছিলো। - হুম ঠিক আছে।  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df = pd.read_csv(os.path.join(data_dir, 'eng2ben - collateral.csv'), names=['English', 'Bengali'], encoding='utf-8')\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Bengali</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      English  Bengali\n",
       "0       False    False\n",
       "1       False    False\n",
       "2       False    False\n",
       "3       False    False\n",
       "4       False    False\n",
       "...       ...      ...\n",
       "1152    False    False\n",
       "1153    False    False\n",
       "1154    False    False\n",
       "1155    False    False\n",
       "1156    False    False\n",
       "\n",
       "[1157 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(main_text):\n",
    "    processed_text = \"\".join([c for c in main_text if c not in string.punctuation and ord(c) != 2404])\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Processed_English'] = df['English'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     You okay  Yeah Im fine mate\n",
       "1                             Dont worry about it\n",
       "2                                   You all right\n",
       "3                                        Enjoy LA\n",
       "4                        He did it  Its all right\n",
       "                          ...                    \n",
       "1152                       I do this for a living\n",
       "1153                 Were almost at the next stop\n",
       "1154                                      Hey Max\n",
       "1155    A guy gets on the MTA here in LA and dies\n",
       "1156                    Think anybody will notice\n",
       "Name: Processed_English, Length: 1157, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Processed_English']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Processed_Bengali'] = df['Bengali'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 আপানি ঠিক আছেন  হ্যাঁ আমি ভালো আছি ভায়া\n",
       "1                           এটা নিয়ে একদম চিন্তা করবেন না\n",
       "2                                        আপনি ঠিক আছেন তো\n",
       "3                          লস এঞ্জেলেসে আসাটা উপভোগ্য হোক\n",
       "4                            সে সেটা করেছিলো  হুম ঠিক আছে\n",
       "                              ...                        \n",
       "1152                   আমি এটা বেঁচে থাকার কাজ হিসাবে করি\n",
       "1153                          আমরা প্রায় শেষ স্টপেজে আছি\n",
       "1154                                          হেই ম্যাক্স\n",
       "1155    লস এঞ্জেলেসে একটা মানুষ ট্রেনে উঠবে  আর সেখানে...\n",
       "1156                   কেউ কি সেটা খেয়াল করবে বলে মনে করো\n",
       "Name: Processed_Bengali, Length: 1157, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Processed_Bengali']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Processed_English'] = df['Processed_English'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     you okay  yeah im fine mate\n",
       "1                             dont worry about it\n",
       "2                                   you all right\n",
       "3                                        enjoy la\n",
       "4                        he did it  its all right\n",
       "                          ...                    \n",
       "1152                       i do this for a living\n",
       "1153                 were almost at the next stop\n",
       "1154                                      hey max\n",
       "1155    a guy gets on the mta here in la and dies\n",
       "1156                    think anybody will notice\n",
       "Name: Processed_English, Length: 1157, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Processed_English']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_english_data(text):\n",
    "    token = re.split('\\W+', text.lstrip().rstrip())\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     [you, okay, yeah, im, fine, mate]\n",
       "1                              [dont, worry, about, it]\n",
       "2                                     [you, all, right]\n",
       "3                                           [enjoy, la]\n",
       "4                        [he, did, it, its, all, right]\n",
       "5     [can, you, tell, me, why, everything, is, alwa...\n",
       "6              [everything, is, not, always, about, me]\n",
       "7     [that, gearhead, with, his, pocket, protector,...\n",
       "8     [and, you, damn, well, know, it, sarcastic, yo...\n",
       "9     [im, sorry, i, just, didnt, see, it, that, way...\n",
       "10    [what, about, the, dig, about, the, makeover, ...\n",
       "11    [what, do, you, want, me, to, do, i, work, wit...\n",
       "12    [and, you, know, what, youre, perfectly, capab...\n",
       "13    [you, know, something, the, last, time, i, che...\n",
       "14    [so, unless, you, want, to, start, fucking, hi...\n",
       "15    [pal, where, can, i, catch, a, shuttle, to, th...\n",
       "16                                [back, there, thanks]\n",
       "17    [it, was, him, in, that, gold, lexus, on, the,...\n",
       "18    [are, they, still, asking, for, a, change, of,...\n",
       "19    [hes, enhanceable, because, of, priors, in, th...\n",
       "Name: Processed_English, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Processed_English'] = df['Processed_English'].apply(lambda x: tokenize_english_data(x))\n",
    "df['Processed_English'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_bengali_data(text):\n",
    "    token = [word for word in text.split()]\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Processed_Bengali'] = df['Processed_Bengali'].apply(lambda x: tokenize_bengali_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [আপানি, ঠিক, আছেন, হ্যাঁ, আমি, ভালো, আছি, ভায়া]\n",
       "1                  [এটা, নিয়ে, একদম, চিন্তা, করবেন, না]\n",
       "2                                 [আপনি, ঠিক, আছেন, তো]\n",
       "3                  [লস, এঞ্জেলেসে, আসাটা, উপভোগ্য, হোক]\n",
       "4                    [সে, সেটা, করেছিলো, হুম, ঠিক, আছে]\n",
       "5     [তুমি, কি, আমাকে, বলতে, পারবে, সবকিছু, কেনো, স...\n",
       "6           [সবকিছু, সবসময়, শুধু, আমাকে, ঘিরে, ঘটে, না]\n",
       "7     [সে, সব, সময়, আমার, সাথে, অন্য, রকম, কিছু, করত...\n",
       "8     [আর, তুমিও, সেটা, ভালো, করেই, জানতে, অন্য, রকম...\n",
       "9     [আমি, দুঃখিত, আমি, আসলে, এটা, আদৌ, এভাবে, দেখত...\n",
       "10    [তুমি, কি, আসলে, দেখেও, না, দেখার, ভান, করতে, ...\n",
       "11    [তুমি, আসলে, আমাকে, দিয়ে, কি, করাতে, চাচ্ছো, আ...\n",
       "12    [আর, তুমি, জানো, কি, তুমি, নিজেই, তোমার, সমস্য...\n",
       "13    [তুমি, কি, একটা, জিনিস, জানো, শেষবার, আমি, চেক...\n",
       "14    [আর, তুমি, এখন, আবার, তাকে, খুশী, করার, চেষ্টা...\n",
       "15    [ভাই, আমি, এয়ারপোর্টে, যাবার, শাটল, কোথা, থেক...\n",
       "16                           [পিছন, দিক, থেকে, ধন্যবাদ]\n",
       "17     [সেটা, ছিলো, সেই, সোনালী, রঙের, লেক্সাস, গাড়িতে]\n",
       "18     [তারা, কি, এখনো, ভ্যানু, পরিবর্তনের, জন্য, বলছে]\n",
       "19    [সে, পারেনি, কারণ, দেশে, এখন, সর্বোচ্চ, তাপমাত...\n",
       "Name: Processed_Bengali, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Processed_Bengali'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1576"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_token_set = set(word for l in df['Processed_English'].values for word in l)\n",
    "len(english_token_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2060"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bengali_token_set = set(word for l in df['Processed_Bengali'].values for word in l)\n",
    "len(bengali_token_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of encoder tokens:  1576\n",
      "Number of decoder tokens:  2061\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens = len(english_token_set)\n",
    "num_decoder_tokens = len(bengali_token_set) + 1\n",
    "\n",
    "print(\"Number of encoder tokens: \", num_encoder_tokens)\n",
    "print(\"Number of decoder tokens: \", num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_word_to_token = dict([(word, i+1) for i, word in enumerate(list(english_token_set))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bengali_word_to_token = dict([(word, i+1) for i, word in enumerate(list(bengali_token_set))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token to word\n",
    "english_token_to_word = dict([i, word] for word, i in english_word_to_token.items())\n",
    "bengali_token_to_word = dict([i, word] for word, i in bengali_word_to_token.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        #embedding taking input dim and then arranging output dim for hidden layers\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
