{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device == torch.device('cuda'):\n",
    "    print(\"Using: \", device)\n",
    "else:\n",
    "    print(\"Using: \", device, \"Training might be slow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'data_preprocessing.ipynb']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_dir = os.getcwd()\n",
    "os.listdir(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder_decoder', 'eng2ben - collateral.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.path.join(working_dir, '..')\n",
    "os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Bengali</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- You okay? - Yeah, I'm fine, mate.</td>\n",
       "      <td>- আপানি ঠিক আছেন? - হ্যাঁ, আমি ভালো আছি, ভায়া।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Don't worry about it.</td>\n",
       "      <td>এটা নিয়ে একদম চিন্তা করবেন না।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You all right?</td>\n",
       "      <td>আপনি ঠিক আছেন তো?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enjoy L.A.</td>\n",
       "      <td>লস এঞ্জেলেসে আসাটা উপভোগ্য হোক।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- He did it. - It's all right.</td>\n",
       "      <td>- সে সেটা করেছিলো। - হুম ঠিক আছে।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               English  \\\n",
       "0  - You okay? - Yeah, I'm fine, mate.   \n",
       "1                Don't worry about it.   \n",
       "2                       You all right?   \n",
       "3                           Enjoy L.A.   \n",
       "4       - He did it. - It's all right.   \n",
       "\n",
       "                                          Bengali  \n",
       "0  - আপানি ঠিক আছেন? - হ্যাঁ, আমি ভালো আছি, ভায়া।  \n",
       "1                  এটা নিয়ে একদম চিন্তা করবেন না।  \n",
       "2                               আপনি ঠিক আছেন তো?  \n",
       "3                 লস এঞ্জেলেসে আসাটা উপভোগ্য হোক।  \n",
       "4               - সে সেটা করেছিলো। - হুম ঠিক আছে।  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df = pd.read_csv(os.path.join(data_dir, 'eng2ben - collateral.csv'), names=['English', 'Bengali'], encoding='utf-8')\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Bengali</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      English  Bengali\n",
       "0       False    False\n",
       "1       False    False\n",
       "2       False    False\n",
       "3       False    False\n",
       "4       False    False\n",
       "...       ...      ...\n",
       "1152    False    False\n",
       "1153    False    False\n",
       "1154    False    False\n",
       "1155    False    False\n",
       "1156    False    False\n",
       "\n",
       "[1157 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = main_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(main_text):\n",
    "    processed_text = \"\".join([c for c in main_text if c not in string.punctuation and ord(c) != 2404])\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Processed_English'] = df['English'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     You okay  Yeah Im fine mate\n",
       "1                             Dont worry about it\n",
       "2                                   You all right\n",
       "3                                        Enjoy LA\n",
       "4                        He did it  Its all right\n",
       "                          ...                    \n",
       "1152                       I do this for a living\n",
       "1153                 Were almost at the next stop\n",
       "1154                                      Hey Max\n",
       "1155    A guy gets on the MTA here in LA and dies\n",
       "1156                    Think anybody will notice\n",
       "Name: Processed_English, Length: 1157, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Processed_English']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Processed_Bengali'] = df['Bengali'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 আপানি ঠিক আছেন  হ্যাঁ আমি ভালো আছি ভায়া\n",
       "1                           এটা নিয়ে একদম চিন্তা করবেন না\n",
       "2                                        আপনি ঠিক আছেন তো\n",
       "3                          লস এঞ্জেলেসে আসাটা উপভোগ্য হোক\n",
       "4                            সে সেটা করেছিলো  হুম ঠিক আছে\n",
       "                              ...                        \n",
       "1152                   আমি এটা বেঁচে থাকার কাজ হিসাবে করি\n",
       "1153                          আমরা প্রায় শেষ স্টপেজে আছি\n",
       "1154                                          হেই ম্যাক্স\n",
       "1155    লস এঞ্জেলেসে একটা মানুষ ট্রেনে উঠবে  আর সেখানে...\n",
       "1156                   কেউ কি সেটা খেয়াল করবে বলে মনে করো\n",
       "Name: Processed_Bengali, Length: 1157, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Processed_Bengali']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Processed_English'] = df['Processed_English'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     you okay  yeah im fine mate\n",
       "1                             dont worry about it\n",
       "2                                   you all right\n",
       "3                                        enjoy la\n",
       "4                        he did it  its all right\n",
       "                          ...                    \n",
       "1152                       i do this for a living\n",
       "1153                 were almost at the next stop\n",
       "1154                                      hey max\n",
       "1155    a guy gets on the mta here in la and dies\n",
       "1156                    think anybody will notice\n",
       "Name: Processed_English, Length: 1157, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Processed_English']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_english_data(text):\n",
    "    token = re.split('\\W+', text.lstrip().rstrip())\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     [you, okay, yeah, im, fine, mate]\n",
       "1                              [dont, worry, about, it]\n",
       "2                                     [you, all, right]\n",
       "3                                           [enjoy, la]\n",
       "4                        [he, did, it, its, all, right]\n",
       "5     [can, you, tell, me, why, everything, is, alwa...\n",
       "6              [everything, is, not, always, about, me]\n",
       "7     [that, gearhead, with, his, pocket, protector,...\n",
       "8     [and, you, damn, well, know, it, sarcastic, yo...\n",
       "9     [im, sorry, i, just, didnt, see, it, that, way...\n",
       "10    [what, about, the, dig, about, the, makeover, ...\n",
       "11    [what, do, you, want, me, to, do, i, work, wit...\n",
       "12    [and, you, know, what, youre, perfectly, capab...\n",
       "13    [you, know, something, the, last, time, i, che...\n",
       "14    [so, unless, you, want, to, start, fucking, hi...\n",
       "15    [pal, where, can, i, catch, a, shuttle, to, th...\n",
       "16                                [back, there, thanks]\n",
       "17    [it, was, him, in, that, gold, lexus, on, the,...\n",
       "18    [are, they, still, asking, for, a, change, of,...\n",
       "19    [hes, enhanceable, because, of, priors, in, th...\n",
       "Name: Processed_English, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Processed_English'] = df['Processed_English'].apply(lambda x: tokenize_english_data(x))\n",
    "df['Processed_English'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_bengali_data(text):\n",
    "    token = [word for word in text.split()]\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Processed_Bengali'] = df['Processed_Bengali'].apply(lambda x: tokenize_bengali_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [আপানি, ঠিক, আছেন, হ্যাঁ, আমি, ভালো, আছি, ভায়া]\n",
       "1                  [এটা, নিয়ে, একদম, চিন্তা, করবেন, না]\n",
       "2                                 [আপনি, ঠিক, আছেন, তো]\n",
       "3                  [লস, এঞ্জেলেসে, আসাটা, উপভোগ্য, হোক]\n",
       "4                    [সে, সেটা, করেছিলো, হুম, ঠিক, আছে]\n",
       "5     [তুমি, কি, আমাকে, বলতে, পারবে, সবকিছু, কেনো, স...\n",
       "6           [সবকিছু, সবসময়, শুধু, আমাকে, ঘিরে, ঘটে, না]\n",
       "7     [সে, সব, সময়, আমার, সাথে, অন্য, রকম, কিছু, করত...\n",
       "8     [আর, তুমিও, সেটা, ভালো, করেই, জানতে, অন্য, রকম...\n",
       "9     [আমি, দুঃখিত, আমি, আসলে, এটা, আদৌ, এভাবে, দেখত...\n",
       "10    [তুমি, কি, আসলে, দেখেও, না, দেখার, ভান, করতে, ...\n",
       "11    [তুমি, আসলে, আমাকে, দিয়ে, কি, করাতে, চাচ্ছো, আ...\n",
       "12    [আর, তুমি, জানো, কি, তুমি, নিজেই, তোমার, সমস্য...\n",
       "13    [তুমি, কি, একটা, জিনিস, জানো, শেষবার, আমি, চেক...\n",
       "14    [আর, তুমি, এখন, আবার, তাকে, খুশী, করার, চেষ্টা...\n",
       "15    [ভাই, আমি, এয়ারপোর্টে, যাবার, শাটল, কোথা, থেক...\n",
       "16                           [পিছন, দিক, থেকে, ধন্যবাদ]\n",
       "17     [সেটা, ছিলো, সেই, সোনালী, রঙের, লেক্সাস, গাড়িতে]\n",
       "18     [তারা, কি, এখনো, ভ্যানু, পরিবর্তনের, জন্য, বলছে]\n",
       "19    [সে, পারেনি, কারণ, দেশে, এখন, সর্বোচ্চ, তাপমাত...\n",
       "Name: Processed_Bengali, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Processed_Bengali'][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1576"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_token_set = set(word for l in df['Processed_English'].values for word in l)\n",
    "len(english_token_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2060"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bengali_token_set = set(word for l in df['Processed_Bengali'].values for word in l)\n",
    "len(bengali_token_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of encoder tokens:  1576\n",
      "Number of decoder tokens:  2061\n"
     ]
    }
   ],
   "source": [
    "num_encoder_tokens = len(english_token_set)\n",
    "num_decoder_tokens = len(bengali_token_set) + 1\n",
    "\n",
    "print(\"Number of encoder tokens: \", num_encoder_tokens)\n",
    "print(\"Number of decoder tokens: \", num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_word_to_token = dict([(word, i+1) for i, word in enumerate(list(english_token_set))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bengali_word_to_token = dict([(word, i+1) for i, word in enumerate(list(bengali_token_set))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#token to word\n",
    "english_token_to_word = dict([i, word] for word, i in english_word_to_token.items())\n",
    "bengali_token_to_word = dict([i, word] for word, i in bengali_word_to_token.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longest sequence in both language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_longest_seq(text, max_len = 0):\n",
    "    if len(text) > max_len:\n",
    "        max_len = len(text)\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sequence in English:  17\n"
     ]
    }
   ],
   "source": [
    "longest_seq_in_english = np.max(df['Processed_English'].apply(lambda x: find_longest_seq(x)))\n",
    "print(\"Longest sequence in English: \", longest_seq_in_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest sequence in Bengali:  19\n"
     ]
    }
   ],
   "source": [
    "longest_seq_in_bengali = np.max(df['Processed_Bengali'].apply(lambda x: find_longest_seq(x)))\n",
    "print(\"Longest sequence in Bengali: \", longest_seq_in_bengali)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        #embedding taking input dim and then arranging output dim for hidden layers\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "        assert encoder.hidden_size == decoder.hidden_size, 'Hidden dimensions of encoder and decoder are not equal'\n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        batch_size = trg.shape[2]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.hidden_size\n",
    "        \n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        enc_output, hidden = self.encoder(src)\n",
    "        input = trg[0, :]\n",
    "        \n",
    "        for i in range(1, trg_len):\n",
    "            output, hidden = self.decoder(enc_output, hidden)\n",
    "            outputs[i] = output\n",
    "            teacher_force = np.random.rand() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[i] if teacher_force else top1\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(english_token_set)\n",
    "OUTPUT_DIM = len(bengali_token_set)\n",
    "HIDDEN_DIM = 512\n",
    "\n",
    "enc = EncoderRNN(INPUT_DIM, HIDDEN_DIM)\n",
    "dec = DecoderRNN(OUTPUT_DIM, HIDDEN_DIM)\n",
    "\n",
    "model = Seq2Seq(enc, dec, device).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(mod):\n",
    "    for name, param in mod.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(1576, 512)\n",
       "    (lstm): LSTM(512, 512)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (lstm): LSTM(512, 512)\n",
       "    (out): Linear(in_features=512, out_features=2060, bias=True)\n",
       "    (softmax): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Total Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(mod):\n",
    "    return sum(parameter.numel() for parameter in mod.parameters() if parameter.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainalbe parameters:  6066188\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of trainalbe parameters: \", count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up loss and optimization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=num_decoder_tokens-1)\n",
    "optimizer = optim.SGD(model.parameters(), momentum=0.9, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
